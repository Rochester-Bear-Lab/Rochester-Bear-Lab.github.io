---
layout: page
---

<h1>Heading 1</h1>
<h2>Heading 2</h2>
<h3>Heading 3</h3>
<h4>Heading 4</h4>

<p>Lorem ipsum.</p>

<button>A button</button>

<p>
  Some more text.
  <a href="#" class="cta">A call to action</a>
</p>


<div class="publication flex mt3">
	<div>
	<img class="h3 mv3 mr3-ns mb2 mb0-ns flex-shrink-0 preview-image ba b--black-05 db" src="assets/people/yukang.png" alt="Teaser image">
      <p> <a href="https://drive.google.com/file/d/1tEYc3sU-ZkGPbUMZ7823E1wyWroyKpHm/view" class="black underline-dot hover-cmu-red link" >CV</a>  | <a href="https://scholar.google.com/citations?user=AXGtrecAAAAJ&hl=en" class="black underline-dot hover-cmu-red link" >Scholar </a> | <a href="yukang.yan@rochester.edu" class="black underline-dot hover-cmu-red link" > Email </a>
    </div>
    <div> 
	<h2>Yukang Yan</h2>


	<p>I'm an Assistant Professor at the Department of Computer Science, University of Rochester. I serve as co-director of ROCHCI Group and lead BEAR Lab. I'm part of the AR/VR Initiative at University of Rochester as a participating faculty. My research is focused in the intersection area of Human-Computer Interaction and Mixed Reality, where I work on both directions of human-system communication. On the output side, I'm interested in understanding how users perceive themselves, digital interfaces and the mixed reality environment, and presenting information in optimized manners, with various goals. On the input side, I model user behavioral patterns while performing different input tasks, and computationally compensate for the inaccuracy in human motor control and reduce noises from the sensory channel. I publish at ACM CHI, UIST, IMWUT, and IEEE VR, with two Best Paper Honorable Mention Awards from CHI 20' and 23', and one Best Paper Nominee Award from VR 23'. I had the great pleasure to work as CHI 24 Late Breaking Work Co-chair with Yomna and Maarten, where three of us managed to coordinate the review process for 1154 submissions. :)</p>
	</div>
</div>


