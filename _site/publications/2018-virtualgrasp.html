<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="x-ua-compatible" content="ie=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="application-name" content="URCS BEAR Lab" />
  <meta name="theme-color" content="#b00" />
  
  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin />
  <link
    href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700&display=swap"
    rel="stylesheet"
  />
  
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@600&display=swap" rel="stylesheet">

  <link
    href="https://use.fontawesome.com/releases/v5.13.0/css/all.css"
    rel="stylesheet"
  />
  <link href="/styles.css" rel="stylesheet" />
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <link rel="shortcut icon" href="/logo.png" />
  <link
    rel="icon"
    type="image/png"
    href="/assets/logo.png"
    sizes="250x250"
  />

  <link
    rel="alternate"
    type="application/rss+xml"
    title="URCS BEAR Lab"
    href="http://localhost:4000/feed.xml"
  />

  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>VirtualGrasp: Leveraging Experience of Interacting with Physical Objects to Facilitate Digital Object Retrieval | URCS BEAR Lab</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="VirtualGrasp: Leveraging Experience of Interacting with Physical Objects to Facilitate Digital Object Retrieval" />
<meta name="author" content="Yukang Yan" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="We propose VirtualGrasp, a novel gestural approach to retrieve virtual objects in virtual reality. Using VirtualGrasp, a user retrieves an object by performing a barehanded gesture as if grasping its physical counterpart. The object-gesture mapping under this metaphor is of high intuitiveness, which enables users to easily discover, remember the gestures to retrieve the objects. We conducted three user studies to demonstrate the feasibility and effectiveness of the approach. Progressively, we investigated the consensus of the object-gesture mapping across users, the expressivity of grasping gestures, and the learnability and performance of the approach. Results showed that users achieved high agreement on the mapping, with an average agreement score [35] of 0.68 (SD=0.27). Without exposure to the gestures, users successfully retrieved 76% objects with VirtualGrasp. A week after learning the mapping, they could recall the gestures for 93% objects." />
<meta property="og:description" content="We propose VirtualGrasp, a novel gestural approach to retrieve virtual objects in virtual reality. Using VirtualGrasp, a user retrieves an object by performing a barehanded gesture as if grasping its physical counterpart. The object-gesture mapping under this metaphor is of high intuitiveness, which enables users to easily discover, remember the gestures to retrieve the objects. We conducted three user studies to demonstrate the feasibility and effectiveness of the approach. Progressively, we investigated the consensus of the object-gesture mapping across users, the expressivity of grasping gestures, and the learnability and performance of the approach. Results showed that users achieved high agreement on the mapping, with an average agreement score [35] of 0.68 (SD=0.27). Without exposure to the gestures, users successfully retrieved 76% objects with VirtualGrasp. A week after learning the mapping, they could recall the gestures for 93% objects." />
<link rel="canonical" href="http://localhost:4000/publications/2018-virtualgrasp.html" />
<meta property="og:url" content="http://localhost:4000/publications/2018-virtualgrasp.html" />
<meta property="og:site_name" content="URCS BEAR Lab" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-10-10T17:05:26-04:00" />
<script type="application/ld+json">
{"headline":"VirtualGrasp: Leveraging Experience of Interacting with Physical Objects to Facilitate Digital Object Retrieval","dateModified":"2023-10-10T17:05:26-04:00","datePublished":"2023-10-10T17:05:26-04:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/publications/2018-virtualgrasp.html"},"url":"http://localhost:4000/publications/2018-virtualgrasp.html","author":{"@type":"Person","name":"Yukang Yan"},"description":"We propose VirtualGrasp, a novel gestural approach to retrieve virtual objects in virtual reality. Using VirtualGrasp, a user retrieves an object by performing a barehanded gesture as if grasping its physical counterpart. The object-gesture mapping under this metaphor is of high intuitiveness, which enables users to easily discover, remember the gestures to retrieve the objects. We conducted three user studies to demonstrate the feasibility and effectiveness of the approach. Progressively, we investigated the consensus of the object-gesture mapping across users, the expressivity of grasping gestures, and the learnability and performance of the approach. Results showed that users achieved high agreement on the mapping, with an average agreement score [35] of 0.68 (SD=0.27). Without exposure to the gestures, users successfully retrieved 76% objects with VirtualGrasp. A week after learning the mapping, they could recall the gestures for 93% objects.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-MSRQ58DGER"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-MSRQ58DGER');
  </script>
</head>



  <body>
    <div class="content">
      <header class="bg-white">
        <div class="w-100 mw8 ph4-l ph3 center pt2 pb4-l pb3 flex items-baseline flex flex-column flex-row-l">
        <!-- <div class="headermenu w-100 mw8 ph4-l ph3 right pt2 pb4-l pb3 flex items-baseline flex flex-column flex-row-l"> -->
        <!-- <div class="headermenu w-100 mw8 pa2 flex flex-column">           -->
          <a href="/" class="dib f2 mt4 fw6 link cmu-dark-gray hover-cmu-red">
          <!-- <a href="/" class="dib f2 mt2 fw6 link black absolute right-0 hover-cmu-red w-55 pa3 mr2"> -->
            <!-- <picture> -->
              <!-- <source  
                srcset="/assets/logo-sphere-01-01-01.svg"
                type="image/svg+xml"              
              /> -->
              <!-- <source
                srcset="/assets/logo-light.webp"
                type="image/webp"
              /> -->
              <!-- <source  
                srcset="/assets/logo-sphere-03-01.png"
                type="image/png"
              />
              <img 
                class="logo"
                alt="A coarsely tesselated sphere colored in shades of gray."
                class="pl2 w3"
              /> -->              
            <!-- </picture> -->
              BEAR Lab
          </a>
          <!--  --><nav class="mt3 ml-auto-ns lh-copy w-auto-ns w-100 flex flex-column flex-row-ns f4 f5-ns">
            <!-- <nav class="mt2 lh-copy w-100 w-25 pa3 mr2"></nav> -->
            <div class="tc mt0-ns mt2">
              <a class="ml4-l ml3-m pa0-ns ph2 pv1 b ur-blue hover-cmu-red link dib  " href="/index">Home</a>
              <a class="ml4-l ml3-m pa0-ns ph2 pv1 b ur-blue hover-cmu-red link dib  " href="/team">Team</a>
              <a class="ml4-l ml3-m pa0-ns ph2 pv1 b ur-blue hover-cmu-red link dib  " href="/publications">Publications</a>
              <!-- <a
                class="ml4-l ml3-m pa0-ns ph2 pv1 b black hover-cmu-red link dib  "
                href="/teaching"
                >Teaching</a
              > -->
              <a class="ml4-l ml3-m pa0-ns ph2 pv1 b ur-blue hover-cmu-red link dib  " href="/contact">Contact</a>
            </div>
          </nav>
        </div>

      </header>

      <main>
        <section>
  <div class="pv4 bg-white">
    <div class="w-100 mw8 ph4-l ph3 pv2-l pv3 center">
      <h1 class="f2 lh-title measure mt3">
        VirtualGrasp: Leveraging Experience of Interacting with Physical Objects to Facilitate Digital Object Retrieval
      </h1>

      

      <div class="mb2">
        
          Yukang Yan,
          Chun Yu,
          Xiaojuan Ma,
          Xin Yi,
          Ke Sun,
          Yuanchun Shi.
        <!-- . -->
        </div>

      <!-- <div class="flex flex-row flex-wrap items-start mt1">
       
        <div class="flex flex-column items-center mt3 mr4">
          <picture>
            <source srcset=""></source>
            <source srcset="/assets/person.png"></source>
            <img class="br-100 w3 h3 mb1" alt="Picture of Yukang Yan" />
          </picture>
          <div class="black mw4 tc">Yukang Yan</div>
        </div>
      
      </div> -->

      
        <div class="mt3">
          Published at
          <span class="b">
            
              <a href="https://chi2018.acm.org/" class="black underline-dot hover-cmu-red link">
            
            ACM CHI
            2018
            </a>
          </span>
        </div>
      

      
    </div>
  </div>

  <div class="w-100 mw8 ph4-l ph3 center mt1">
    
    <img src="/assets/publications/2018-virtualgrasp.png" alt="Teaser image" class="mw-100" style="max-height: 600px">

    

    
    
      <h2>Abstract</h2>
      <div class="lh-copy">
        We propose VirtualGrasp, a novel gestural approach to retrieve virtual objects in virtual reality. Using VirtualGrasp, a user retrieves an object by performing a barehanded gesture as if grasping its physical counterpart. The object-gesture mapping under this metaphor is of high intuitiveness, which enables users to easily discover, remember the gestures to retrieve the objects. We conducted three user studies to demonstrate the feasibility and effectiveness of the approach. Progressively, we investigated the consensus of the object-gesture mapping across users, the expressivity of grasping gestures, and the learnability and performance of the approach. Results showed that users achieved high agreement on the mapping, with an average agreement score [35] of 0.68 (SD=0.27). Without exposure to the gestures, users successfully retrieved 76% objects with VirtualGrasp. A week after learning the mapping, they could recall the gestures for 93% objects.
      </div>
    

    <!-- width="400" height="240" class="thumb-video"  -->
    

    
    <h2>Materials</h2>
      <ul class="list pl0">
        
          <li class="mt2"><a href="https://dl.acm.org/doi/pdf/10.1145/3173574.3173652" class="black link hover-cmu-red underline-dot ">
            PDF
          </a></li>
        

        

        

        

        

        

        

        

        
        
      </ul>
    

    
      <h2>Bibtex</h2>
      <div class="f6 underline-dot">
        <pre>@inproceedings{yukang20182, author = {Yan, Yukang and Yu, Chun and Ma, Xiaojuan and Yi, Xin and Sun, Ke and Shi, Yuanchun}, title = {VirtualGrasp: Leveraging Experience of Interacting with Physical Objects to Facilitate Digital Object Retrieval}, year = {2018}, isbn = {9781450356206}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3173574.3173652}, doi = {10.1145/3173574.3173652}, abstract = {}, booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems}, pages = {1–13}, numpages = {13}, keywords = {gesture, mapping, object selection}, location = {Montreal QC, Canada}, series = {CHI '18} }</pre>
      </div>
    
    
  </div>
</section>

      </main>
    </div>

    <footer class="bt white mt5 flex-shrink-0">
      <div class="w-100 mw8 ph4-l ph3 center pv3 footerinfo">
        <ul class="list pl0">
          <li>
            <a href="/index" class="link white dib underline-dot-white hover-cmu-red mv1">BEAR Lab</a>, 
            <a href="https://www.cs.rochester.edu" class="link white dib underline-dot-white hover-cmu-red mv1">Department of Computer Science</a>,
            <a href="https://rochester.edu/" class="link white dib underline-dot-white hover-cmu-red mv1">University of Rochester</a>
            <!-- <span ></span>  -->
          </li>
          <li>
            <span>
            Wegmans Hall, 250 Hutchison Rd, Rochester, NY 14620 United States, <a href="/contact" class="link white dim underline-dot-white hover-cmu-red">How to find us.</a>
            </span>
          </li>
          <li class="pv1">
            <abbr title="Last build on 2023-10-10" class="white" style="list-style: height 2em; text-decoration: none;">Last update October 2023</abbr>              
          </li>
        </ul>
      </div>
    </footer>
  </body>
</html>
