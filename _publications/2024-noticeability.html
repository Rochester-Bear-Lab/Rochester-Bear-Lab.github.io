---
layout: publication
year: 2024
month: 05
selected: false
coming-soon: false
hidden: false
link: https://dl.acm.org/doi/full/10.1145/3613904.3642399
pdf: https://dl.acm.org/doi/pdf/10.1145/3613904.3642399
title: "Predicting the Noticeability of Dynamic Virtual Elements in Virtual Reality"
authors:
  - Zhipeng Li
  - Yi Fei Cheng
  - Yukang Yan
  - David Lindlbauer
# blog: https://ait.ethz.ch/projects/2020/omni/
doi: 10.1145/3613904.3642399
venue_location: Honolulu, HI, USA
venue_url: https://chi2024.acm.org/
venue_tags:
  - CHI
type:
  - Conference
tags:
  - Science
  - Mixed Reality
  - Perception
venue: CHI

video-thumb: fMi5m9fYEIg
#video-30sec: 4E5Ca-bVsxU
#video-suppl: vRyM7TEQHWM
#video-talk-5min: UvP8FJ9Q0x8
#video-talk-15min: V7Qi6Mdsxak

bibtex: "@inproceedings{zhipeng24,
author = {Li, Zhipeng and Cheng, Yi Fei and Yan, Yukang and Lindlbauer, David},
title = {Predicting the Noticeability of Dynamic Virtual Elements in Virtual Reality},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642399},
doi = {10.1145/3613904.3642399},
abstract = {},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {954},
numpages = {17},
keywords = {Computational Interaction, Mixed Reality, Virtual Reality},
location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
series = {CHI '24}
}"

---

While Virtual Reality (VR) systems can present virtual elements such as notifications anywhere, designing them so they are not missed by or distracting to users is highly challenging for content creators. To address this challenge, we introduce a novel approach to predict the noticeability of virtual elements. It computes the visual saliency distribution of what users see, and analyzes the temporal changes of the distribution with respect to the dynamic virtual elements that are animated. The computed features serve as input for a long short-term memory (LSTM) model that predicts whether a virtual element will be noticed. Our approach is based on data collected from 24 users in different VR environments performing tasks such as watching a video or typing. We evaluate our approach (n = 12), and show that it can predict the timing of when users notice a change to a virtual element within 2.56 sec compared to a ground truth, and demonstrate the versatility of our approach with a set of applications. We believe that our predictive approach opens the path for computational design tools that assist VR content creators in creating interfaces that automatically adapt virtual elements based on noticeability.
<br/>
<br/>

