---
layout: publication
year: 2020
month: 5
selected: true
coming-soon: false
hidden: false
external : false
link: https://dl.acm.org/doi/abs/10.1145/3313831.3376810
pdf: https://dl.acm.org/doi/pdf/10.1145/3313831.3376810
title: "FrownOnError: Interrupting Responses from Smart Speakers by Facial Expressions"
authors:
  - Yukang Yan
  - Chun Yu
  - Wengrui Zheng
  - Ruining Tang
  - Xuhai Xu
  - Yuanchun Shi
# blog: https://ait.ethz.ch/projects/2020/omni/
doi: 10.1145/3313831.3376836
# venue_location: Virtual
venue_url: https://chi2020.acm.org/
venue_tags:
  - ACM CHI
type:
  - Conference
tags:
  - Science
  - Sensing
  - Voice Interface
venue: ACM CHI
awards: Best Paper Honorable Mention Award

# video-thumb: N9RPUSfnBac
# video-30sec: N9RPUSfnBac
# video-suppl: XatgUCTpCWQ
# video-talk-5min: ISR7eQgD5x8
# video-talk-15min: q7PoZ-jGN3I

bibtex: "@inproceedings{yukang2020,
author = {Yan, Yukang and Yu, Chun and Zheng, Wengrui and Tang, Ruining and Xu, Xuhai and Shi, Yuanchun},
title = {FrownOnError: Interrupting Responses from Smart Speakers by Facial Expressions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376810},
doi = {10.1145/3313831.3376810},
abstract = {},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1â€“14},
numpages = {14},
keywords = {voice user interface, conversation interruption, facial expression},
location = {Honolulu, HI, USA},
series = {CHI '20}
}"

---

In the conversations with smart speakers, misunderstandings of users' requests lead to erroneous responses. We propose FrownOnError, a novel interaction technique that enables users to interrupt the responses by intentional but natural facial expressions. This method leverages the human nature that the facial expression changes when we receive unexpected responses. We conducted a first user study (N=12) to understand users' intuitive reactions to the correct and incorrect responses. Our results reveal the significant difference in the frequency of occurrence and intensity of users' facial expressions between two conditions, and frowning and raising eyebrows are intuitive to perform and easy to control. Our second user study (N=16) evaluated the user experience and interruption efficiency of FrownOnError and the third user study (N=12) explored suitable conversation recovery strategies after the interruptions. Our results show that FrownOnError can be accurately detected (precision: 97.4%, recall: 97.6%), provides the most timely interruption compared to the baseline methods of wake-up word and button press, and is rated as most intuitive and easiest to be performed by users.