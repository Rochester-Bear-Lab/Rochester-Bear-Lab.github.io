---
layout: publication
year : 2019
month: 10
selected: true
hidden: false
external : false
link: https://dl.acm.org/doi/abs/10.1145/3332165.3347950
pdf: https://dl.acm.org/doi/pdf/10.1145/3332165.3347950
title: "PrivateTalk: Activating Voice Input with Hand-On-Mouth Gesture Detected by Bluetooth Earphones"
authors:
  - Yukang Yan
  - Chun Yu
  - Yingtian Shi
  - Minxing Xie
#blog: https://ait.ethz.ch/projects/2019/computationalMR/
#code: https://github.com/eth-ait/ComputationalMR
doi: 10.1145/3332165.3347950
venue_location: New Orleans
venue_url: https://uist.acm.org/uist2019/
venue_tags:
  - UIST
type:
  - Conference
tags:
  - Science
  - Voice Interface
  - Sensing
venue: UIST

#video-thumb: aGuwwWka0Fk
#video-30sec: aGuwwWka0Fk
#video-suppl: heAGuCsWs9o
# video-talk-5min: ...
#video-talk-15min: SAmmTUw96Mg

bibtex: "@inproceedings{yukang2019,
author = {Yan, Yukang and Yu, Chun and Shi, Yingtian and Xie, Minxing},
title = {PrivateTalk: Activating Voice Input with Hand-On-Mouth Gesture Detected by Bluetooth Earphones},
year = {2019},
isbn = {9781450368162},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3332165.3347950},
doi = {10.1145/3332165.3347950},
abstract = {},
booktitle = {Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology},
pages = {1013â€“1020},
numpages = {8},
keywords = {voice input, hand gesture},
location = {New Orleans, LA, USA},
series = {UIST '19}
}"
---

We introduce PrivateTalk, an on-body interaction technique that allows users to activate voice input by performing the Hand-On-Mouth gesture during speaking. The gesture is performed as a hand partially covering the mouth from one side. PrivateTalk provides two benefits simultaneously. First, it enhances privacy by reducing the spread of voice while also concealing the lip movements from the view of other people in the environment. Second, the simple gesture removes the need for speaking wake-up words and is more accessible than a physical/software button especially when the device is not in the user's hands. To recognize the Hand-On-Mouth gesture, we propose a novel sensing technique that leverages the difference of signals received by two Bluetooth earphones worn on the left and right ear. Our evaluation shows that the gesture can be accurately detected and users consistently like PrivateTalk and consider it intuitive and effective.
