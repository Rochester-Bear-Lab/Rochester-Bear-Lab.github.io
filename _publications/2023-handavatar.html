---
layout: publication
year: 2023
month: 05
selected: true
coming-soon: false
hidden: false
external : false
# link: https://dl.acm.org/doi/10.1145/3472749.3474750
pdf: https://doi.org/10.1145/3544548.3581027
title: "HandAvatar: Embodying Non-Humanoid Virtual Avatars through Hands"
authors:
  - Yu Jiang*
  - Zhipeng Li*
  - Mufei He
  - David Lindlbauer
  - Yukang Yan
# blog: https://ait.ethz.ch/projects/2020/omni/
doi: 10.1145/3544548.3581027
venue_location: Hamburg, Germany
venue_url: https://chi2023.acm.org/
venue_tags:
  - ACM CHI
type:
  - Conference
tags:
  - Science
  - Mixed Reality
  - Animiation
  - Hand tracking
venue: ACM CHI

video-thumb: 4OiMxRwrJHM
video-30sec: 4OiMxRwrJHM
video-suppl: GAvys0HLqw0
#video-talk-5min: l9ycUrf50TE
video-talk-15min: EJwMmeSN01Q

bibtex: "@inproceedings {Jiang23, \n
author = {Jiang, Yu and Li, Zhipeng and He, Mufei and Lindlbauer, David and Yan, Yukang}, \n
title = {HandAvatar: Embodying Non-Humanoid Virtual Avatars through Hands}, \n
year = {2023}, \n
publisher = {Association for Computing Machinery}, \n
address = {New York, NY, USA}, \n
url = {https://doi.org/10.1145/3544548.3581027}, \n
doi = {10.1145/3544548.3581027}, \n
keywords = {virtual avatar, embodiment, Mixed Reality, gestural interaction}, \n
location = {Hamburg, Germany}, \n
series = {CHI '23} \n
}"

---

We propose HandAvatar to enable users to embody non-humanoid avatars using their hands. HandAvatar leverages the high dexterity and coordination of users' hands to control virtual avatars, enabled through our novel approach for automatically-generated joint-to-joint mappings. We contribute an observation study to understand usersâ€™ preferences on hand-to-avatar mappings on eight avatars. Leveraging insights from the study, we present an automated approach that generates mappings between users' hands and arbitrary virtual avatars by jointly optimizing control precision, structural similarity, and comfort. We evaluated HandAvatar on static posing, dynamic animation, and creative exploration tasks. Results indicate that HandAvatar enables more precise control, requires less physical effort, and brings comparable embodiment compared to a state-of-the-art body-to-avatar control method. We demonstrate HandAvatar's potential with applications including non-humanoid avatar based social interaction in VR, 3D animation composition, and VR scene design with physical proxies. We believe that HandAvatar unlocks new interaction opportunities, especially for usage in Virtual Reality, by letting users become the avatar in applications including virtual social interaction, animation, gaming, or education.