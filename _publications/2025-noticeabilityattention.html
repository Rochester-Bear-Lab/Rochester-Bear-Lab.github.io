---
layout: publication
year: 2025
month: 05
selected: true
coming-soon: true
hidden: false
#link: https://drive.google.com/file/d/1VwF1wU8uCYLG68qZVn1rz1nbMrNwDFwf/view?usp=sharing
#pdf: https://drive.google.com/file/d/1VwF1wU8uCYLG68qZVn1rz1nbMrNwDFwf/view?usp=sharing
title: "Modeling the Impact of Visual Stimuli on Redirection Noticeability with Gaze Behavior in Virtual Reality"
authors:
  - Zhipeng Li
  - Yishu Ji
  - Ruijia Chen
  - Tianqi Liu
  - Yuntao Wang
  - Yuanchun Shi
  - Yukang Yan
# blog: https://ait.ethz.ch/projects/2020/omni/
#doi: 10.1145/3613904.3642747
venue_location: Saint-Malo, France
venue_url: https://ieeevr.org/2025/
venue_tags:
  - CHI
type:
  - Conference
tags:
  - Science
  - Behavior Modeling
venue: CHI

video-thumb: 0SEPpIeQbJA
#video-30sec: 4E5Ca-bVsxU
#video-suppl: vRyM7TEQHWM
#video-talk-5min: UvP8FJ9Q0x8
#video-talk-15min: V7Qi6Mdsxak


---

While users could embody virtual avatars that mirror their physical movements in Virtual Reality, these avatars' motions can be redirected to enable novel interactions. Excessive redirection, however, could break the user's sense of embodiment due to perceptual conflicts between vision and proprioception. While prior work focused on avatar-related factors influencing the noticeability of redirection, we investigate how the visual stimuli in the surrounding virtual environment affect user behavior and, in turn, the noticeability of redirection. Given the wide variety of different types of visual stimuli and their tendency to elicit varying individual reactions, we propose to use users' gaze behavior as an indicator of their response to the stimuli and model the noticeability of redirection. We conducted two user studies to collect users' gaze behavior and noticeability, investigating the relationship between them and identifying the most effective gaze behavior features for predicting noticeability. Based on the data, we developed a regression model that takes users' gaze behavior as input and outputs the noticeability of redirection. We then conducted an evaluation study to test our model on unseen visual stimuli, achieving an accuracy of 0.012 MSE. We further implemented an adaptive redirection technique and conducted a proof-of-concept study to evaluate its effectiveness with complex visual stimuli in two applications. The results indicated that participants experienced less physical demanding and a stronger sense of body ownership when using our adaptive technique, demonstrating the potential of our model to support real-world use cases.

