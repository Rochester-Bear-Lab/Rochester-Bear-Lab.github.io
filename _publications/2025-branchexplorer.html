---
layout: publication
year: 2025
month: 09
selected: false
coming-soon: false
hidden: false
link: https://dl.acm.org/doi/abs/10.1145/3746059.3747791
pdf: https://dl.acm.org/doi/pdf/10.1145/3746059.37477912
title: "Branch Explorer: Leveraging Branching Narratives to Support Interactive 360° Video Viewing for Blind and Low Vision Users"
authors:
  - Shuchang Xu
  - Xiaofu Jin
  - Wenshuo Zhang
  - Huamin Qu
  - Yukang Yan
# blog: https://ait.ethz.ch/projects/2020/omni/
doi: 10.1145/3706598.3713392
venue_location: Yokohama, Japan
venue_url: https://chi2025.acm.org/
venue_tags:
  - CHI
type:
  - Conference
tags:
  - Science
  - Behavior Modeling
venue: CHI

video-thumb: 0SEPpIeQbJA
#video-30sec: 4E5Ca-bVsxU
#video-suppl: vRyM7TEQHWM
#video-talk-5min: UvP8FJ9Q0x8
#video-talk-15min: V7Qi6Mdsxak


bibtex: "@inproceedings{10.1145/3706598.3713392,
author = {Li, Zhipeng and Ji, Yishu and Chen, Ruijia and Liu, Tianqi and Wang, Yuntao and Shi, Yuanchun and Yan, Yukang},
title = {Modeling the Impact of Visual Stimuli on Redirection Noticeability with Gaze Behavior in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713392},
doi = {10.1145/3706598.3713392},
abstract = {While users could embody virtual avatars that mirror their physical movements in Virtual Reality, these avatars’ motions can be redirected to enable novel interactions. Excessive redirection, however, could break the user’s sense of embodiment due to perceptual conflicts between vision and proprioception. While prior work focused on avatar-related factors influencing the noticeability of redirection, we investigate how the visual stimuli in the surrounding virtual environment affect user behavior and, in turn, the noticeability of redirection. Given the wide variety of different types of visual stimuli and their tendency to elicit varying individual reactions, we propose to use users’ gaze behavior as an indicator of their response to the stimuli and model the noticeability of redirection. We conducted two user studies to collect users’ gaze behavior and noticeability, investigating the relationship between them and identifying the most effective gaze behavior features for predicting noticeability. Based on the data, we developed a regression model that takes users’ gaze behavior as input and outputs the noticeability of redirection. We then conducted an evaluation study to test our model on unseen visual stimuli, achieving an accuracy of 0.012 MSE. We further implemented an adaptive redirection technique and conducted a preliminary study to evaluate its effectiveness with complex visual stimuli in two applications. The results indicated that participants experienced less physical demanding and a stronger sense of body ownership when using our adaptive technique, demonstrating the potential of our model to support real-world use cases.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {38},
numpages = {18},
keywords = {Virtual Reality, visual attention, noticeability, embodiment},
location = {
},
series = {CHI '25}
}"

---

While users could embody virtual avatars that mirror their physical movements in Virtual Reality, these avatars' motions can be redirected to enable novel interactions. Excessive redirection, however, could break the user's sense of embodiment due to perceptual conflicts between vision and proprioception. While prior work focused on avatar-related factors influencing the noticeability of redirection, we investigate how the visual stimuli in the surrounding virtual environment affect user behavior and, in turn, the noticeability of redirection. Given the wide variety of different types of visual stimuli and their tendency to elicit varying individual reactions, we propose to use users' gaze behavior as an indicator of their response to the stimuli and model the noticeability of redirection. We conducted two user studies to collect users' gaze behavior and noticeability, investigating the relationship between them and identifying the most effective gaze behavior features for predicting noticeability. Based on the data, we developed a regression model that takes users' gaze behavior as input and outputs the noticeability of redirection. We then conducted an evaluation study to test our model on unseen visual stimuli, achieving an accuracy of 0.012 MSE. We further implemented an adaptive redirection technique and conducted a proof-of-concept study to evaluate its effectiveness with complex visual stimuli in two applications. The results indicated that participants experienced less physical demanding and a stronger sense of body ownership when using our adaptive technique, demonstrating the potential of our model to support real-world use cases.

